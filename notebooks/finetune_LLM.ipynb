{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is for finetuning an autoregressive language model (like OPT or GPT2) for recognizing medical symptom mentions"
      ],
      "metadata": {
        "id": "wM04of_H8wI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Qe7OZMBh3LPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1YmwSK9wGxm"
      },
      "outputs": [],
      "source": [
        "! pip install datasets transformers\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Format data"
      ],
      "metadata": {
        "id": "bjpGyionT3q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/labeled_patient_records.txt\")\n",
        "\n",
        "# create a list of all symptoms mentioned\n",
        "symptom_label_list = list(df['symptom_label'].value_counts().keys())\n",
        "symptom_label_list = [x.lower() for x in symptom_label_list]\n",
        "\n",
        "text_list = []\n",
        "for i, row in df.iterrows():\n",
        "  symptom = ''\n",
        "  person_mention = ''\n",
        "  if row['no_symptom']:\n",
        "    # if the record does not mention any symptom, set the prompt to a random \n",
        "    # symptom and train the model to respond that the symptom was not found\n",
        "    symptom = random.choice(symptom_label_list)\n",
        "    person_mention = 'not mentioned'\n",
        "  else:\n",
        "    symptom = row['symptom_label']\n",
        "\n",
        "    symptom = symptom.lower()\n",
        "\n",
        "  text = \"\"\"Patient medical file:\n",
        "{}\n",
        "\n",
        "Symptom: {}\n",
        "Mention in relation to patient: {} \n",
        "\"\"\".format(row[\"transcription\"], symptom, person_mention)\n",
        "\n",
        "  text_list.append(text)\n"
      ],
      "metadata": {
        "id": "v6YQw4UiT5j5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "HYZyLwe_Th-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_MODEL = \"facebook/opt-350m\"\n",
        "MODEL_MAX_LEN = 2048\n",
        "OUTPUT_PATH = \"/models/final\" # where final model will be saved"
      ],
      "metadata": {
        "id": "-Knh-vEBTBaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    default_data_collator,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, model_max_length=MODEL_MAX_LEN)\n",
        "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/tmp/model\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    learning_rate=1e-5\n",
        ")\n",
        "\n",
        "def encode(batch):\n",
        "    encodings = tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)\n",
        "    encodings[\"labels\"] = encodings[\"input_ids\"].copy()\n",
        "    return encodings"
      ],
      "metadata": {
        "id": "iWLc_uzu5_cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_load = Dataset.from_dict({\"text\": text_list})\n",
        "tokenized_datasets = dataset_load.map(encode, remove_columns=[\"text\"])\n",
        "\n",
        "model.cuda() # train on gpu\n",
        "\n",
        "trainer = Trainer(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets,\n",
        "    data_collator=default_data_collator\n",
        ")\n",
        "trainer.train()\n",
        "trainer.save_model(OUTPUT_PATH)"
      ],
      "metadata": {
        "id": "EyDscmSBz8x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "pw5sWQyaTk0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GenerationConfig"
      ],
      "metadata": {
        "id": "zHDn-uzC7pS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example:\n",
        "text = \"\"\"Patient medical file:\n",
        "PREOPERATIVE DIAGNOSIS: , Missed abortion.,POSTOPERATIVE DIAGNOSIS:  ,Missed abortion.,PROCEDURE PERFORMED: , Suction, dilation, and curettage.,ANESTHESIA: , Spinal.,ESTIMATED BLOOD LOSS:,  50 mL.,COMPLICATIONS: , None.,FINDINGS: , Products of conception consistent with a 6-week intrauterine pregnancy.,INDICATIONS: , The patient is a 28-year-old gravida 4, para 3 female at 13 weeks by her last menstrual period and 6 weeks by an ultrasound today in the emergency room who presents with heavy bleeding starting today.  A workup done in the emergency room revealed a beta-quant level of 1931 and an ultrasound showing an intrauterine pregnancy with a crown-rump length consistent with a 6-week and 2-day pregnancy.  No heart tones were visible.  On examination in the emergency room, a moderate amount of bleeding was noted.,Additionally, the cervix was noted to be 1 cm dilated.  These findings were discussed with the patient and options including surgical management via dilation and curettage versus management with misoprostol versus expected management were discussed with the patient.  After discussion of these options, the patient opted for a suction, dilation, and curettage.  The patient was described to the patient in detail including risks of infection, bleeding, injury to surrounding organs including risk of perforation.  Informed consent was obtained prior to proceeding with the procedure.,PROCEDURE NOTE:  ,The patient was taken to the operating room where spinal anesthesia was administered without difficulty.  The patient was prepped and draped in usual sterile fashion in lithotomy position.  A weighted speculum was placed.  The anterior lip of the cervix was grasped with a single tooth tenaculum.  At this time, a 7-mm suction curettage was advanced into the uterine cavity without difficulty and was used to suction contents of the uterus.  Following removal of the products of conception, a sharp curette was advanced into the uterine cavity and was used to scrape the four walls of the uterus until a gritty texture was noted.  At this time, the suction curette was advanced one additional time to suction any remaining products.  All instruments were removed.  Hemostasis was visualized.  The patient was stable at the completion of the procedure.  Sponge, lap, and instrument counts were correct.\n",
        "\n",
        "Symptom: joint pain\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LO1nASv_8hny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(text, return_tensors='pt').cuda()\n",
        "\n",
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "     generation_config=GenerationConfig(temperature=0, max_length=1024)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Sswp9Ns1Uij",
        "outputId": "1faaa3ee-be15-4e24-a8c3-166daeb95ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (1024) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(sample_output[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "h7IPq-W-2LCA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}